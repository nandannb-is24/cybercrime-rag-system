# ‚öñÔ∏è CyberCrime Legal Assistant

<div align="center">



**An AI-powered legal assistant providing grounded cybercrime guidance using RAG technology**


</div>

---

## üìã Table of Contents

- Overview
- Features
- System Architecture
- Tech Stack
- Getting Started
  - Prerequisites
  - Installation
  - Configuration
- Usage
- Project Structure
- API Reference
- Dataset
- Acknowledgments

---

## üéØ Overview

CyberCrime Legal Assistant is a **Retrieval-Augmented Generation (RAG)** system that provides accurate, grounded legal guidance on cybercrime cases. Unlike traditional chatbots, this system retrieves relevant case law from a vector database and generates responses backed by real legal precedents.

### Why RAG?

- **Grounded Responses**: Answers are based on actual case data, not hallucinations
- **Transparent Citations**: Every response includes source case references
- **Up-to-date Information**: Easy to update the knowledge base with new cases
- **Domain-Specific Accuracy**: Specialized for cybercrime legal queries

> **Note**: This system is for educational and informational purposes only. Always consult a qualified legal professional for official legal advice.

---

## ‚ú® Features

### Core Capabilities

- üîç **Semantic Search**: ChromaDB-powered vector search for finding relevant cases
- üß† **LLM Reasoning**: Groq (LLaMA 3.1) for natural language generation
- üìö **Case Citations**: Transparent source attribution with case references
- ‚ö° **Fast Inference**: Groq's infrastructure ensures sub-second response times
- üé® **Modern UI**: React-based chat interface with dark mode support

### User Experience

- üí¨ Real-time chat interface
- üìù Context-aware responses
- üåì Dark/Light mode toggle
- üì± Responsive design
- üíæ Chat history persistence

---

## üèóÔ∏è System Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   User Query    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  React Frontend ‚îÇ
‚îÇ   (Chat UI)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  FastAPI/Flask  ‚îÇ
‚îÇ   Backend API   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  RAG Pipeline   ‚îÇ
‚îÇ  rag_pipeline.py‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚ñº         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇChromaDB‚îÇ ‚îÇ Groq ‚îÇ
‚îÇVector  ‚îÇ ‚îÇ LLM  ‚îÇ
‚îÇ  DB    ‚îÇ ‚îÇ      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ         ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚ñº
  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  ‚îÇ   Response   ‚îÇ
  ‚îÇ + Citations  ‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Pipeline Flow

1. **User Input**: Query submitted via React chat interface
2. **Embedding**: Query converted to vector embedding
3. **Retrieval**: ChromaDB finds top-K most relevant cases
4. **Context Formation**: Retrieved cases formatted as context
5. **Generation**: Groq LLM generates response with citations
6. **Display**: Answer shown in UI with source references

---

## üõ†Ô∏è Tech Stack

### Backend
- **Python 3.11+** - Core language
- **ChromaDB** - Vector database for semantic search
- **Groq API** - Ultra-fast LLM inference
- **LLaMA 3.1** - Large language model
- **FastAPI/Flask** - REST API framework
- **SentenceTransformers** - Text embeddings

### Frontend
- **React 18+** - UI framework
- **Vite** - Build tool
- **Tailwind CSS** - Styling
- **Lucide React** - Icons

---

## üöÄ Getting Started

### Prerequisites

- Python 3.11 or higher
- Node.js 18+ and npm
- Git
- Groq API key ([Get one here](https://console.groq.com))

### Installation

#### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/legalchatbot.git
cd legalchatbot
```

#### 2. Backend Setup

```bash
# Create virtual environment
python -m venv .venv

# Activate virtual environment on Windows:
.venv\Scripts\activate
# On macOS/Linux:
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

#### 3. Frontend Setup

```bash
cd frontend
npm install
```

#### 4. Environment Configuration

Create a `.env` file in the root directory:

```env
GROQ_API_KEY=your_groq_api_key_here
CHROMA_DB_PATH=./cyber_crime_db
MODEL_NAME=llama-3.1-70b-versatile
```

#### 5. Data Ingestion

```bash
# Run from project root
python backend/app/rag/ingest.py
```

This will:
- Load cases from `data/cases.json`
- Generate embeddings
- Store vectors in ChromaDB

---

## üíª Usage

### Development Mode

**Terminal 1 - Backend:**
```bash
# Activate virtual environment
source .venv/bin/activate  # or .venv\Scripts\activate on Windows

# Run backend (from root)
cd backend
python main.py
```

**Terminal 2 - Frontend:**
```bash
cd frontend
npm run dev
```

Visit `http://localhost:5173` in your browser.

### Production Build

```bash
# Frontend
cd frontend
npm run build

# Serve with backend
cd ../backend
python main.py --production
```

### CLI Testing

Test retrieval only:
```bash
python backend/app/rag/query.py "What are the penalties for UPI fraud?"
```

Test full RAG pipeline:
```bash
python backend/app/rag/rag_pipeline.py "Someone hacked my Instagram account"
```

---

## üìÅ Project Structure

```
LEGALCHATBOT/
‚îÇ
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rag/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __pycache__/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ glue.py              # ChromaDB connection
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ingest.py            # Data ingestion pipeline
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llm.py               # Groq LLM integration
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ query.py             # Retrieval module
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __pycache__/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.py                  # FastAPI/Flask app
‚îÇ   ‚îú‚îÄ‚îÄ chroma_db/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 9daf0607-df43-4f00-b74a-bee8515933f0/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chroma.sqlite3
‚îÇ   ‚îú‚îÄ‚îÄ cyber_crime_db/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 5aa79a53-ae29-48d7-8a63-45cdfa1ca21c/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chroma.sqlite3
‚îÇ   ‚îî‚îÄ‚îÄ .venv/                       # Virtual environment
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ cases.json                   # Cybercrime case dataset
‚îÇ
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ node_modules/
‚îÇ   ‚îú‚îÄ‚îÄ public/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ law.svg.svg              # Law icon/logo
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Client.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ assets/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ react.svg
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Background.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ BoundaryDemo.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ComparisonTable.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ExampleQueries.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Message.jsx          # Chat message component
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ RagFlow.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ScrollReveal.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SourceCard.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SourcePreview.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ StatsCard.jsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Chat.jsx             # Main chat page
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ landing.jsx          # Landing page
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.css
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.jsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index.css
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.jsx
‚îÇ   ‚îú‚îÄ‚îÄ .gitignore
‚îÇ   ‚îú‚îÄ‚îÄ components.json
‚îÇ   ‚îú‚îÄ‚îÄ eslint.config.js
‚îÇ   ‚îú‚îÄ‚îÄ index.html
‚îÇ   ‚îú‚îÄ‚îÄ jsconfig.json
‚îÇ   ‚îú‚îÄ‚îÄ package-lock.json
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îú‚îÄ‚îÄ postcss.config.js
‚îÇ   ‚îú‚îÄ‚îÄ README.md
‚îÇ   ‚îú‚îÄ‚îÄ tailwind.config.js
‚îÇ   ‚îî‚îÄ‚îÄ vite.config.js
‚îÇ
‚îú‚îÄ‚îÄ __pycache__/
‚îú‚îÄ‚îÄ .venv/                           # Virtual environment
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ requirements.txt                 # Python dependencies
```

---

## üîå API Reference

### Base URL
```
http://localhost:5000/api
```

### Endpoints

#### POST `/ask`
Get legal guidance on a cybercrime query.

**Request:**
```json
{
  "question": "I lost money in a UPI fraud. What should I do?",
  "top_k": 5
}
```

**Response:**
```json
{
  "answer": "Based on relevant case law, you should immediately...",
  "sources": [
    "IPC Section 420 - Cheating and Dishonesty",
    "IT Act 2000 Section 66D - Punishment for cheating by personation"
  ],
  "context_used": 5
}
```

#### GET `/health`
Check API health status.

**Response:**
```json
{
  "status": "healthy",
  "database": "connected",
  "model": "llama-3.1-70b-versatile"
}
```

---

## üìä Dataset

The system uses a curated dataset of cybercrime cases stored in `data/cases.json`.

### Schema

```json
{
  "case_id": "CC001",
  "title": "UPI Fraud Case",
  "category": "financial_fraud",
  "description": "Victim lost ‚Çπ50,000 through unauthorized UPI transaction...",
  "relevant_laws": ["IPC 420", "IT Act 66D"],
  "verdict": "Guilty - 2 years imprisonment + ‚Çπ1,00,000 fine",
  "precedent": "Similar cases should report to cybercrime cell within 24 hours"
}
```

### Data Sources

> **Important**: The dataset is compiled from publicly available cybercrime case summaries for educational and research purposes only.


### Coding Standards

- Follow PEP 8 for Python code
- Use ESLint/Prettier for JavaScript
- Write meaningful commit messages
- Add tests for new features
- Update documentation


##  Acknowledgments

- **ChromaDB Team** - For the excellent vector database
- **Groq** - For providing fast LLM inference
- **Meta AI** - For the LLaMA model
- **Indian Legal Community** - For publicly available case data


<div align="center">


**TEAM JUSTICE LEAGUE**

</div>